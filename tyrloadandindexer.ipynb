{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语义分析划分段落\n",
    "\n",
    "from langchain_community.document_loaders import (PyPDFLoader)\n",
    "# 换一个OCR？\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import (SentenceTransformerEmbeddings,)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ltp import StnSplit\n",
    "\n",
    "\n",
    "path_docfolder = \"STPDF\"\n",
    "path_db = \"STDB\"\n",
    "\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n",
    "\n",
    "THRESHOLD = 70\n",
    "    \n",
    "\n",
    "class SemanticParagraphSplitter:\n",
    "    def __init__(self, threshold=THRESHOLD, model_path=model_name):\n",
    "        self.threshold = threshold\n",
    "        self.model = SentenceTransformer(model_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def cut_sentences(text):\n",
    "        sentences = StnSplit().split(text)\n",
    "        return sentences\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_sentences(sentences, buffer_size=2):\n",
    "        # Go through each sentence dict\n",
    "        for i in range(len(sentences)):\n",
    "\n",
    "            # Create a string that will hold the sentences which are joined\n",
    "            combined_sentence = ''\n",
    "\n",
    "            # Add sentences before the current one, based on the buffer size.\n",
    "            for j in range(i - buffer_size, i):\n",
    "                # Check if the index j is not negative (to avoid index out of range like on the first one)\n",
    "                if j >= 0:\n",
    "                    # Add the sentence at index j to the combined_sentence string\n",
    "                    combined_sentence += sentences[j]['sentence'] + ' '\n",
    "\n",
    "            # Add the current sentence\n",
    "            combined_sentence += sentences[i]['sentence']\n",
    "\n",
    "            # Add sentences after the current one, based on the buffer size\n",
    "            for j in range(i + 1, i + 1 + buffer_size):\n",
    "                # Check if the index j is within the range of the sentences list\n",
    "                if j < len(sentences):\n",
    "                    # Add the sentence at index j to the combined_sentence string\n",
    "                    combined_sentence += ' ' + sentences[j]['sentence']\n",
    "\n",
    "            # Then add the whole thing to your dict\n",
    "            # Store the combined sentence in the current sentence dict\n",
    "            sentences[i]['combined_sentence'] = combined_sentence\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    def build_sentences_dict(self, sentences):\n",
    "        indexed_sentences = [{'sentence': x, 'index': i} for i, x in enumerate(sentences)]\n",
    "        combined_sentences = self.combine_sentences(indexed_sentences)\n",
    "\n",
    "        embeddings = self.model.encode([x['combined_sentence'] for x in combined_sentences], normalize_embeddings=True)\n",
    "\n",
    "        for i, sentence in enumerate(combined_sentences):\n",
    "            sentence['combined_sentence_embedding'] = embeddings[i]\n",
    "\n",
    "        return combined_sentences\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_cosine_distances(sentences):\n",
    "        distances = []\n",
    "        for i in range(len(sentences) - 1):\n",
    "            embedding_current = sentences[i]['combined_sentence_embedding']\n",
    "            embedding_next = sentences[i + 1]['combined_sentence_embedding']\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            # similarity = cosine_similarity([embedding_current], [embedding_next])[0][0]\n",
    "            similarity = embedding_current @ embedding_next.T\n",
    "            # Convert to cosine distance\n",
    "            distance = 1 - similarity\n",
    "\n",
    "            # Append cosine distance to the list\n",
    "            distances.append(distance)\n",
    "\n",
    "            # Store distance in the dictionary\n",
    "            sentences[i]['distance_to_next'] = distance\n",
    "\n",
    "        # Optionally handle the last sentence\n",
    "        # sentences[-1]['distance_to_next'] = None  # or a default value\n",
    "\n",
    "        return distances, sentences\n",
    "\n",
    "    def calculate_indices_above_thresh(self, distances):\n",
    "        breakpoint_distance_threshold = np.percentile(distances, self.threshold)\n",
    "        # The indices of those breakpoints on your list\n",
    "        indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold]\n",
    "        return indices_above_thresh\n",
    "\n",
    "    @staticmethod\n",
    "    def cut_chunks(indices_above_thresh, sentences):\n",
    "        # Initialize the start index\n",
    "        start_index = 0\n",
    "\n",
    "        # Create a list to hold the grouped sentences\n",
    "        chunks = []\n",
    "\n",
    "        # Iterate through the breakpoints to slice the sentences\n",
    "        for index in indices_above_thresh:\n",
    "            # The end index is the current breakpoint\n",
    "            end_index = index\n",
    "\n",
    "            # Slice the sentence_dicts from the current start index to the end index\n",
    "            group = sentences[start_index:end_index + 1]\n",
    "            combined_text = ' '.join([d['sentence'] for d in group])\n",
    "            chunks.append(combined_text)\n",
    "\n",
    "            # Update the start index for the next group\n",
    "            start_index = index + 1\n",
    "\n",
    "        # The last group, if any sentences remain\n",
    "        if start_index < len(sentences):\n",
    "            combined_text = ' '.join([d['sentence'] for d in sentences[start_index:]])\n",
    "            chunks.append(combined_text)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def split(self, text):\n",
    "        single_sentences = (self.cut_sentences(text)) #Pre-split with standard function\n",
    "        print(f\"{len(single_sentences)} single sentences were found\")\n",
    "        if len(single_sentences) == 1:\n",
    "        # 如果只有一句话，直接返回这句话\n",
    "            return single_sentences\n",
    "        else:\n",
    "        # 如果有多句话，进行分割\n",
    "            chunks = self.split_passages(single_sentences)\n",
    "            return chunks\n",
    "    def split_passages(self, passages):\n",
    "        combined_sentences = self.build_sentences_dict(passages)\n",
    "        distances, sentences = self.calculate_cosine_distances(combined_sentences)\n",
    "\n",
    "        indices_above_thresh = self.calculate_indices_above_thresh(distances)\n",
    "        chunks = self.cut_chunks(indices_above_thresh, sentences)\n",
    "        return chunks\n",
    "\n",
    "def read_pdf_files_in_folder_onebyone_and_Store(path_docfolder, path_db, embedding):\n",
    "    # Iterate over all files in the folder\n",
    "    full_content = []\n",
    "    for filename in os.listdir(path_docfolder):\n",
    "        #print(filename)\n",
    "        if filename.endswith('.pdf'):  # Check if the file is a PDF\n",
    "            file_path = os.path.join(path_docfolder, filename)\n",
    "            print(f\"Reading file: {file_path}\")\n",
    "\n",
    "            # Open the PDF file\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            pages_pypdf = loader.load()\n",
    "            for page in pages_pypdf:\n",
    "                # 内容全合并在一起\n",
    "                full_content.append(page.page_content.replace(\" \", \"\").replace(\"\\n\", \"\"))\n",
    "\n",
    "    text_splitter = SemanticParagraphSplitter(threshold=THRESHOLD)\n",
    "            # text_splitter = RecursiveCharacterTextSplitter(\n",
    "            #     chunk_size=260,\n",
    "            #     chunk_overlap=20,\n",
    "            # )\n",
    "    for content in full_content:\n",
    "        docs = text_splitter.split(content)\n",
    "        \n",
    "\n",
    "    # Facility Step 3:用特定模型做embedding\n",
    "    #db2 = Chroma.from_documents(docs, embedding, persist_directory=path_db)\n",
    "        db2 = Chroma.from_texts(docs, embedding, persist_directory=path_db)\n",
    "        print(\"Successfully save the embedding into DB\")\n",
    "    return True\n",
    "\n",
    "read_pdf_files_in_folder_onebyone_and_Store(path_docfolder, path_db, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "path_db = \"STDB\"\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name)\n",
    "vectorstore = Chroma(persist_directory=path_db, embedding_function=embedding)\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.prompts.chat import ChatPromptTemplate,SystemMessagePromptTemplate,HumanMessagePromptTemplate,AIMessagePromptTemplate,MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "# from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "import os\n",
    "\n",
    "os.environ['VLLM_USE_MODELSCOPE']='True'\n",
    "chat=ChatOpenAI(\n",
    "    model=\"qwen/Qwen-7B-Chat-Int4\",\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base='http://localhost:8000/v1',\n",
    "    # stop=['<|im_end|>']\n",
    ")\n",
    "\n",
    "# Prompt模板\n",
    "system_prompt=SystemMessagePromptTemplate.from_template('You are a knowledge base quiz assistant.')\n",
    "user_prompt=HumanMessagePromptTemplate.from_template('''\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context1}\n",
    "\n",
    "Question: {query1}\n",
    "''')\n",
    "full_chat_prompt=ChatPromptTemplate.from_messages([system_prompt,MessagesPlaceholder(variable_name=\"chat_history1\"),user_prompt])\n",
    "\n",
    "\n",
    "# Chat chain\n",
    "chat_chain={\n",
    "        \"context1\": itemgetter(\"retrievers\"),\n",
    "        \"query1\": itemgetter(\"query\"),\n",
    "        \"chat_history1\":itemgetter(\"chat_history\"),\n",
    "    }|full_chat_prompt|chat\n",
    "\n",
    "# 开始对话\n",
    "chat_history=[]\n",
    "while True:\n",
    "    query=input('query:')\n",
    "    retriever = vectorstore.similarity_search(query,k=20)\n",
    "    response=chat_chain.invoke({'retrievers':retriever,'query':query,'chat_history':chat_history})\n",
    "    chat_history.extend((HumanMessage(content=query),response))\n",
    "    print(response.content)\n",
    "    chat_history=chat_history[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter方法分词存入数据库\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import (SentenceTransformerEmbeddings,)\n",
    "\n",
    "path_docfolder = \"STPDF\"\n",
    "path_db = \"STDB1\"\n",
    "\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n",
    "\n",
    "for filename in os.listdir(path_docfolder):\n",
    "    if filename.endswith('.pdf'): \n",
    "        file_path = os.path.join(path_docfolder, filename)\n",
    "        # Open the PDF file\n",
    "        pdf_loader = PyPDFLoader(file_path,extract_images=True)\n",
    "        # 解析PDF，切成chunk片段\n",
    "        chunks=pdf_loader.load_and_split(text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100))\n",
    "        for doc in chunks:\n",
    "            doccontent = doc.page_content \n",
    "            db2 = Chroma.from_texts(doccontent, embedding_function, persist_directory=path_db)\n",
    "        print(\"Successfully save the embedding into DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama+rag\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader,WebbaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_spiltters import CharacterTextSpiltters\n",
    "\n",
    "model_local=ChatOllama(model='')\n",
    "# Split into chunks\n",
    "\n",
    "urls = [\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "docs = [WebbaseLoader(urls).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "text_spiltters = CharacterTextSpiltters.from_tikton_encoder(chunk_size=7500,chunk_overlap=100)\n",
    "doc_spilts = text_spiltters.spilt_documents(docs_list)\n",
    "\n",
    "# embedding and store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = doc_spilts,\n",
    "    collection_name = \"webbase\",\n",
    "    embedding = embeddings.ollama.OllamaEmbeddings(model='') \n",
    ")\n",
    "\n",
    "retreiver = vectorstore.as_retreiver()\n",
    "\n",
    "# before RAG\n",
    "print(\"==================================before RAG================================\")\n",
    "before_rag_temolate = \"what is {topic}\"\n",
    "before_rag_prompt = ChatPromptTemplate.from_template(before_rag_temolate)\n",
    "before_rag_chain = before_rag_prompt | model_local | StrOutputParser()\n",
    "print(before_rag_chain.invoke({\"topic\":\"Ollama\"}))\n",
    "\n",
    "# after RAG\n",
    "print(\"==================================after RAG================================\")\n",
    "after_rag_temolate ='''\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {query}\n",
    "'''\n",
    "after_rag_temolate = ChatPromptTemplate.from_template(after_rag_temolate)\n",
    "after_rag_chain = (\n",
    "    {\"context\":retriever,\"query\": RunnablePassthrough()}\n",
    "    | after_rag_temolate\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(after_rag_chain.invoke({\"what is Ollama\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama + gradio\n",
    "import gradio as gr\n",
    "from langchain_community.document_loaders import PyPDFLoader,WebbaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_spiltters import CharacterTextSpiltters\n",
    "from langchian.output_parsers import PydanticOutputParser\n",
    "\n",
    "def process_input(urls,question):\n",
    "    model_local = ChatOllama(model=\"\")\n",
    "    urls_list = urls.split(\"\\n\")\n",
    "    docs = [WebbaseLoader(url) for url in urls_list]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "    text_spiltter = CharacterTextSpiltters.from_text_encoder(chunk_size=7500,chunk_overlap=100)\n",
    "    doc_spilts = text_spiltter.spilt_documents(docs_list)\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_spilts,   \n",
    "        collection_name=\"webbase\",\n",
    "        embedding=embeddings.ollama.OllamaEmbeddings(model=\"\")\n",
    "    )\n",
    "    retreiver = vectorstore.as_retreiver()\n",
    "    after_rag_template ='''\n",
    "    Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question: {query}\n",
    "    '''\n",
    "    after_rag_template = ChatPromptTemplate.from_template(after_rag_template)\n",
    "    after_rag_chain = (\n",
    "        {\"context\":retreiver,\"query\":RunnablePassthrough()}\n",
    "        | after_rag_template\n",
    "        | model_local\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return after_rag_chain.invoke({\"query\":question})\n",
    "\n",
    "# define  Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_input,\n",
    "    inputs=[gr.Textbox(label=\"enter input\"),gr.Textbox(label=\"Question\")],\n",
    "    outputs=\"text\",\n",
    "    title=\"Ollama Chat\",\n",
    "    description=\"Chat with Ollama\"\n",
    ")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接提问无上传文件版本 + ollama + gradio langchain效果不好？不知道为什么...\n",
    "import gradio as gr\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "path_db = \"STDB\"\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name)\n",
    "vectorstore = Chroma(persist_directory=path_db, embedding_function=embedding)\n",
    "\n",
    "\n",
    "def process_input(question):\n",
    "    model_local = ChatOllama(model=\"\")\n",
    "    retreiver = vectorstore.similarity_search(question,k=10)\n",
    "    after_rag_template ='''\n",
    "    Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question: {query}\n",
    "    '''\n",
    "    after_rag_template = ChatPromptTemplate.from_template(after_rag_template)\n",
    "    after_rag_chain = (\n",
    "        {\"context\":retreiver,\"query\":RunnablePassthrough()}\n",
    "        | after_rag_template\n",
    "        | model_local\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return after_rag_chain.invoke({\"query\":question})\n",
    "\n",
    "# define  Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_input,\n",
    "    inputs=gr.Textbox(label=\"请提出你的问题\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"llm Chat\",\n",
    "    description=\"根据已上传的文件内容进行问答\"\n",
    ")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不用langchain版本，ollama+gradio 流式和非流式\n",
    "\n",
    "import ollama\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import gradio as gr\n",
    "\n",
    "path_db = \"STDB\"\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name)\n",
    "vectorstore = Chroma(persist_directory=path_db, embedding_function=embedding)   \n",
    "\n",
    "def process_input(query):\n",
    "    retriever = vectorstore.similarity_search(query,k=3)\n",
    "    context = retriever\n",
    "    prompt=f'''\n",
    "    Answer the question based only on the following context:\n",
    "\n",
    "    \"{context}\"\n",
    "\n",
    "    Question: {query}\n",
    "    '''\n",
    "    # print(prompt)\n",
    "    # 修改model\n",
    "    stream = ollama.chat(model='wangrongsheng/mistral-7b-v0.3-chinese-chat', messages=[{'role': 'user', 'content': f\"{prompt}\"}], stream=False)\n",
    "    return stream['message']['content']\n",
    "\n",
    "    # 流式\n",
    "    # stream = ollama.chat(model='wangrongsheng/mistral-7b-v0.3-chinese-chat', messages=[{'role': 'user', 'content': f\"{prompt}\"}], stream=True)\n",
    "    # output = \"\"\n",
    "    # for con in stream:\n",
    "    #     output += con['message']['content']\n",
    "    #     yield output\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=process_input,\n",
    "    inputs=gr.Textbox(label=\"请提出你的问题\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"llm Chat\",\n",
    "    description=\"根据已上传的文件内容进行问答\"\n",
    ")\n",
    "iface.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传pdf版本 + ollama + gradio\n",
    "import gradio as gr\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.text_spiltters import CharacterTextSpiltters\n",
    "from langchian.output_parsers import PydanticOutputParser\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from langchain_community.embeddings.sentence_transformer import (SentenceTransformerEmbeddings,)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ltp import StnSplit\n",
    "\n",
    "path_docfolder = \"STPDF\"\n",
    "path_db = \"STDB\"\n",
    "\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=model_name)\n",
    "\n",
    "THRESHOLD = 70\n",
    "    \n",
    "\n",
    "class SemanticParagraphSplitter:\n",
    "    def __init__(self, threshold=THRESHOLD, model_path=model_name):\n",
    "        self.threshold = threshold\n",
    "        self.model = SentenceTransformer(model_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def cut_sentences(text):\n",
    "        sentences = StnSplit().split(text)\n",
    "        return sentences\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_sentences(sentences, buffer_size=2):\n",
    "        # Go through each sentence dict\n",
    "        for i in range(len(sentences)):\n",
    "\n",
    "            # Create a string that will hold the sentences which are joined\n",
    "            combined_sentence = ''\n",
    "\n",
    "            # Add sentences before the current one, based on the buffer size.\n",
    "            for j in range(i - buffer_size, i):\n",
    "                # Check if the index j is not negative (to avoid index out of range like on the first one)\n",
    "                if j >= 0:\n",
    "                    # Add the sentence at index j to the combined_sentence string\n",
    "                    combined_sentence += sentences[j]['sentence'] + ' '\n",
    "\n",
    "            # Add the current sentence\n",
    "            combined_sentence += sentences[i]['sentence']\n",
    "\n",
    "            # Add sentences after the current one, based on the buffer size\n",
    "            for j in range(i + 1, i + 1 + buffer_size):\n",
    "                # Check if the index j is within the range of the sentences list\n",
    "                if j < len(sentences):\n",
    "                    # Add the sentence at index j to the combined_sentence string\n",
    "                    combined_sentence += ' ' + sentences[j]['sentence']\n",
    "\n",
    "            # Then add the whole thing to your dict\n",
    "            # Store the combined sentence in the current sentence dict\n",
    "            sentences[i]['combined_sentence'] = combined_sentence\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    def build_sentences_dict(self, sentences):\n",
    "        indexed_sentences = [{'sentence': x, 'index': i} for i, x in enumerate(sentences)]\n",
    "        combined_sentences = self.combine_sentences(indexed_sentences)\n",
    "\n",
    "        embeddings = self.model.encode([x['combined_sentence'] for x in combined_sentences], normalize_embeddings=True)\n",
    "\n",
    "        for i, sentence in enumerate(combined_sentences):\n",
    "            sentence['combined_sentence_embedding'] = embeddings[i]\n",
    "\n",
    "        return combined_sentences\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_cosine_distances(sentences):\n",
    "        distances = []\n",
    "        for i in range(len(sentences) - 1):\n",
    "            embedding_current = sentences[i]['combined_sentence_embedding']\n",
    "            embedding_next = sentences[i + 1]['combined_sentence_embedding']\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            # similarity = cosine_similarity([embedding_current], [embedding_next])[0][0]\n",
    "            similarity = embedding_current @ embedding_next.T\n",
    "            # Convert to cosine distance\n",
    "            distance = 1 - similarity\n",
    "\n",
    "            # Append cosine distance to the list\n",
    "            distances.append(distance)\n",
    "\n",
    "            # Store distance in the dictionary\n",
    "            sentences[i]['distance_to_next'] = distance\n",
    "\n",
    "        # Optionally handle the last sentence\n",
    "        # sentences[-1]['distance_to_next'] = None  # or a default value\n",
    "\n",
    "        return distances, sentences\n",
    "\n",
    "    def calculate_indices_above_thresh(self, distances):\n",
    "        breakpoint_distance_threshold = np.percentile(distances, self.threshold)\n",
    "        # The indices of those breakpoints on your list\n",
    "        indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold]\n",
    "        return indices_above_thresh\n",
    "\n",
    "    @staticmethod\n",
    "    def cut_chunks(indices_above_thresh, sentences):\n",
    "        # Initialize the start index\n",
    "        start_index = 0\n",
    "\n",
    "        # Create a list to hold the grouped sentences\n",
    "        chunks = []\n",
    "\n",
    "        # Iterate through the breakpoints to slice the sentences\n",
    "        for index in indices_above_thresh:\n",
    "            # The end index is the current breakpoint\n",
    "            end_index = index\n",
    "\n",
    "            # Slice the sentence_dicts from the current start index to the end index\n",
    "            group = sentences[start_index:end_index + 1]\n",
    "            combined_text = ' '.join([d['sentence'] for d in group])\n",
    "            chunks.append(combined_text)\n",
    "\n",
    "            # Update the start index for the next group\n",
    "            start_index = index + 1\n",
    "\n",
    "        # The last group, if any sentences remain\n",
    "        if start_index < len(sentences):\n",
    "            combined_text = ' '.join([d['sentence'] for d in sentences[start_index:]])\n",
    "            chunks.append(combined_text)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def split(self, text):\n",
    "        single_sentences = (self.cut_sentences(text)) #Pre-split with standard function\n",
    "        print(f\"{len(single_sentences)} single sentences were found\")\n",
    "        if len(single_sentences) == 1:\n",
    "        # 如果只有一句话，直接返回这句话\n",
    "            return single_sentences\n",
    "        else:\n",
    "        # 如果有多句话，进行分割\n",
    "            chunks = self.split_passages(single_sentences)\n",
    "            return chunks\n",
    "    def split_passages(self, passages):\n",
    "        combined_sentences = self.build_sentences_dict(passages)\n",
    "        distances, sentences = self.calculate_cosine_distances(combined_sentences)\n",
    "\n",
    "        indices_above_thresh = self.calculate_indices_above_thresh(distances)\n",
    "        chunks = self.cut_chunks(indices_above_thresh, sentences)\n",
    "        return chunks\n",
    "\n",
    "def read_pdf_files_in_folder_onebyone_and_Store(path_docfolder, path_db, embedding):\n",
    "    # Iterate over all files in the folder\n",
    "    full_content = []\n",
    "    for filename in os.listdir(path_docfolder):\n",
    "        #print(filename)\n",
    "        if filename.endswith('.pdf'):  # Check if the file is a PDF\n",
    "            file_path = os.path.join(path_docfolder, filename)\n",
    "            print(f\"Reading file: {file_path}\")\n",
    "\n",
    "            # Open the PDF file\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            pages_pypdf = loader.load()\n",
    "            for page in pages_pypdf:\n",
    "                # 内容全合并在一起\n",
    "                full_content.append(page.page_content.replace(\" \", \"\").replace(\"\\n\", \"\"))\n",
    "\n",
    "    text_splitter = SemanticParagraphSplitter(threshold=THRESHOLD)\n",
    "            # text_splitter = RecursiveCharacterTextSplitter(\n",
    "            #     chunk_size=260,\n",
    "            #     chunk_overlap=20,\n",
    "            # )\n",
    "    for content in full_content:\n",
    "        docs = text_splitter.split(content)\n",
    "        \n",
    "\n",
    "    # Facility Step 3:用特定模型做embedding\n",
    "    #db2 = Chroma.from_documents(docs, embedding, persist_directory=path_db)\n",
    "        db2 = Chroma.from_texts(docs, embedding, persist_directory=path_db)\n",
    "        print(\"Successfully save the embedding into DB\")\n",
    "    return True\n",
    "\n",
    "read_pdf_files_in_folder_onebyone_and_Store(path_docfolder, path_db, embedding_function)\n",
    "\n",
    "\n",
    "def process_input(urls,question):\n",
    "    model_local = ChatOllama(model=\"\")\n",
    "    urls_list = urls.split(\"\\n\")\n",
    "    docs = [WebbaseLoader(url) for url in urls_list]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "    text_spiltter = CharacterTextSpiltters.from_text_encoder(chunk_size=7500,chunk_overlap=100)\n",
    "    doc_spilts = text_spiltter.spilt_documents(docs_list)\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_spilts,   \n",
    "        collection_name=\"webbase\",\n",
    "        embedding=embeddings.ollama.OllamaEmbeddings(model=\"\")\n",
    "    )\n",
    "    retreiver = vectorstore.as_retreiver()\n",
    "    after_rag_template ='''\n",
    "    Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question: {query}\n",
    "    '''\n",
    "    after_rag_template = ChatPromptTemplate.from_template(after_rag_template)\n",
    "    after_rag_chain = (\n",
    "        {\"context\":retreiver,\"query\":RunnablePassthrough()}\n",
    "        | after_rag_template\n",
    "        | model_local\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return after_rag_chain.invoke({\"query\":question})\n",
    "\n",
    "# define  Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_input,\n",
    "    inputs=[gr.Files(accept=\".pdf\",label=\"请上传pdf文件\"),gr.Textbox(label=\"请提出你的问题\")],\n",
    "    outputs=\"text\",\n",
    "    title=\"llm Chat\",\n",
    "    description=\"根据已上传的文件内容进行问答\"\n",
    ")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['线路中央计算机系统', '管理与控制城市轨道交通线路自动售检票系统的计算机系统']\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "#import ollama \n",
    "# 加载Word文档\n",
    "doc = Document('E:\\ganhuo\\INESANETliterature\\文件夹\\软件测试案例方案\\术语.docx')\n",
    "\n",
    "tables=doc.tables\n",
    "row_data1=[]\n",
    "for i in range(len(tables)):\n",
    "    tb=tables[i]\n",
    "    #获取表格的行\n",
    "    tb_rows=tb.rows\n",
    "    #读取每一行内容\n",
    "\n",
    "    for i in range(len(tb_rows)):\n",
    "        if i!=0:\n",
    "            row_data=[]\n",
    "            row_cells=tb_rows[i].cells\n",
    "            #读取每一行单元格内容\n",
    "            for cell in row_cells:\n",
    "                #单元格内容\n",
    "                row_data.append(cell.text)\n",
    "            # print(row_data)\n",
    "            row_data1.append(row_data)\n",
    "       \n",
    "# jsonlist=[]\n",
    "\n",
    "# for data in row_data1:\n",
    "#     prompt=f'''\n",
    "#     请仅基于我发你的文字生成格式如为下的json问答\n",
    "#     格式为：\n",
    "#     {{\n",
    "#         \"instruction\": \"\",\n",
    "#         \"input\": \"\",\n",
    "#         \"output\": \"\"\n",
    "#         }}\n",
    "#     例子：\n",
    "#     输入：['自动售检票系统', '是基于计算机技术、网络技术、自动控制技术等技术能够实现购票、检票、计费、收费、统计全过程的自动化系统。']\n",
    "#     生成：\n",
    "#     {{\n",
    "#         \"instruction\": \"请问自动售检票系统是什么\",\n",
    "#         \"input\": \"\",\n",
    "#         \"output\": \"是基于计算机技术、网络技术、自动控制技术等技术能够实现购票、检票、计费、收费、统计全过程的自动化系统。\"\n",
    "#     }}\n",
    "#     输入：['AID', 'Application Identifier', '应用标识']\n",
    "#     生成：\n",
    "#     {{\n",
    "#         \"instruction\": \"请问AID是什么意思\",\n",
    "#         \"input\": \"\",\n",
    "#         \"output\": \"英文为Application Identifier，中文为应用标识\"\n",
    "#     }}\n",
    "#     输入：{data}\n",
    "\n",
    "#     '''\n",
    "#     context = ollama.chat(model='wangrongsheng/mistral-7b-v0.3-chinese-chat', messages=[{'role': 'user', 'content': f\"{prompt}\"}], stream=False)\n",
    "#     jsonlist.append(context['message']['content'])\n",
    "#     print(jsonlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
